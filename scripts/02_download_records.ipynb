{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f5c17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import lxml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import playwright\n",
    "from configparser import ConfigParser\n",
    "from urllib.parse import urljoin\n",
    "import json\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba983356",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the range of directory names (from \"104\" to \"118\")\n",
    "start_year = 104\n",
    "end_year = 118\n",
    "\n",
    "directory = '../records'\n",
    "os.makedirs(directory, exist_ok=False)\n",
    "\n",
    "# Iterate through the range and create directories\n",
    "for year in range(start_year, end_year + 1):\n",
    "    # Create the main directory (e.g., \"104\")\n",
    "    main_directory = f\"../records/session {str(year)}\"\n",
    "    os.makedirs(main_directory, exist_ok=False)\n",
    "\n",
    "    # Create subdirectories \"senate\" and \"house\" within the main directory\n",
    "    senate_directory = os.path.join(main_directory, \"senate\")\n",
    "    house_directory = os.path.join(main_directory, \"house\")\n",
    "\n",
    "    os.makedirs(senate_directory, exist_ok=False)\n",
    "    os.makedirs(house_directory, exist_ok=False)\n",
    "\n",
    "    print(f\"Created directories for year {year}:\")\n",
    "    print(f\"- {main_directory}\")\n",
    "    print(f\"  - senate\")\n",
    "    print(f\"  - house\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5723ab",
   "metadata": {},
   "source": [
    "## Download Records (House)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cd26f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = [104,105,106,107,108,109,110,111,112,113,114,115,116,117,118]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d54874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download a PDF from a URL and save it with a unique filename\n",
    "def download_house(url, filename):\n",
    "    counter = 1\n",
    "    while os.path.exists(filename):\n",
    "        # Append a counter to the filename\n",
    "        filename = os.path.join(download_dir, f\"house_{date_part}_{counter}.pdf\")\n",
    "        counter += 1\n",
    "\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(filename, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"Downloaded: {filename}\")\n",
    "    else:\n",
    "        print(f\"Failed to download: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62242f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "\n",
    "for s in session:\n",
    "    # Specify the path to your text file\n",
    "    file_path = f'../records_links/house_links_{s}.txt'\n",
    "    # Open the file in read mode\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Read each line and append it to the list\n",
    "        for line in file:\n",
    "            urls.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b107235",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for s in session:\n",
    "    # Directory where you want to save the downloaded files\n",
    "    download_dir = f'../records/session {s}/house'\n",
    "    # Iterate through the PDF links and download each PDF\n",
    "    for url in urls:\n",
    "        # Extract the date part from each link (e.g., \"1995/12/30\")\n",
    "        date_part = url.split('/')[-6:-3]\n",
    "        date_part = \"-\".join(date_part)\n",
    "\n",
    "        # Construct the initial filename with the \"house\" prefix and date part\n",
    "        initial_filename = os.path.join(download_dir, f\"house_{date_part}.pdf\")\n",
    "\n",
    "        # Download the PDF with a unique filename\n",
    "        download_house(url, initial_filename)\n",
    "    \n",
    "        # Add a 1-second break before the next download\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a453e9",
   "metadata": {},
   "source": [
    "## Download Records (Senate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77df0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = [104,105,106,107,108,109,110,111,112,113,114,115,116,117,118]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b819bb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download a PDF from a URL and save it with a unique filename\n",
    "def download_senate(url, filename):\n",
    "    counter = 1\n",
    "    while os.path.exists(filename):\n",
    "        # Append a counter to the filename\n",
    "        filename = os.path.join(download_dir, f\"senate_{date_part}_{counter}.pdf\")\n",
    "        counter += 1\n",
    "\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(filename, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"Downloaded: {filename}\")\n",
    "    else:\n",
    "        print(f\"Failed to download: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5094be29",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "\n",
    "for s in session:\n",
    "    # Specify the path to your text file\n",
    "    file_path = f'../records_links/senate_links_{s}.txt'\n",
    "    # Open the file in read mode\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Read each line and append it to the list\n",
    "        for line in file:\n",
    "            urls.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb4e820",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for s in session:\n",
    "    # Directory where you want to save the downloaded files\n",
    "    download_dir = f'../records/session {s}/senate'\n",
    "    # Iterate through the PDF links and download each PDF\n",
    "    for url in urls:\n",
    "        # Extract the date part from each link (e.g., \"1995/12/30\")\n",
    "        date_part = url.split('/')[-6:-3]\n",
    "        date_part = \"-\".join(date_part)\n",
    "\n",
    "        # Construct the initial filename with the \"house\" prefix and date part\n",
    "        initial_filename = os.path.join(download_dir, f\"senate_{date_part}.pdf\")\n",
    "\n",
    "        # Download the PDF with a unique filename\n",
    "        download_senate(url, initial_filename)\n",
    "    \n",
    "        # Add a 1-second break before the next download\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73c5b06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
